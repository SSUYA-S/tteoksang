{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "# 이거는 테스트용!!!!!!!!!!!!!!!!!!\n",
    "# 크롤러를 만들기 전 필요한 도구 임포트\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import os\n",
    "import asyncio\n",
    "import requests\n",
    "import json\n",
    "import traceback\n",
    "import aiofiles\n",
    "\n",
    "news_code = 101\n",
    "stop_count = 500\n",
    "\n",
    "# 형태소 분석 시작\n",
    "# pip install konlpy 터미널에 입력 후 시작\n",
    "# Mecab 이란 것도 있긴 하나 안됨...시도도 하지 마시오...(제발)\n",
    "# 데이터 정제\n",
    "from konlpy.tag import Okt\n",
    "tokenizer = Okt()\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "stopwords = ['멘트', '앵커', '기자', 'KBS', 'MBC', 'SBS', '와', '과', '가', '의', '이', '은', '등', '을', '이다', '했다', '구독', \n",
    "            'http', 'https',':', '···', '…', '’', '‘', 'ⓒ', \"!\", \"'\", '\"', '는', '를', '=', '[', ']', '(', ')', '.', ',','·', '으로', '로', '에', '도', '고']\n",
    "containwords = ['할인', '상승', '하락', '물가', '가격', '비싸', '금액', '제사', '마트', '장바구니']\n",
    "specific_words = ['쌀', '찹쌀', '콩', '팥', '녹두', '메밀', '고구마', '감자', '귀리', '혼합곡', '보리', '수수', '율무', '기장', '배추', '양배추', '알배기배추', '브로콜리', '시금치', '상추', '얼갈이 배추',\n",
    "                '갓', '수박', '참외', '오이', '호박', '토마토', '딸기', '무', '당근', '열무', '건고추', '풋고추', '붉은고추', '고추', '피마늘', '깐마늘', '마늘', '양파', '파', '생강', '고춧가루', '가지',\n",
    "                '미나리', '깻잎', '부추', '피망', '파프리카', '멜론', '브로콜리', '양상추', '상추', '청경채', '케일', '콩나물', '방울토마토', '연근', '우엉', '절임배추', '참깨', '들깨', '땅콩', '느타리버섯',\n",
    "                '팽이버섯', '새송이버섯', '버섯', '호두', '아몬드', '양송이버섯', '표고버섯', '견과류', '사과', '배', '복숭아', '포도', '감귤', '귤', '단감', '감', '바나나', '참다래', '파인애플', '오렌지',\n",
    "                '자몽', '레몬', '체리', '건포도', '건블루베리', '망고', '아보카도', '블루베리',\n",
    "                '수확', '김장', '채소', '과일', '농가', '식재료', '수확', '작황', '농산물','농작물', '생육', '곡물']\n",
    "\n",
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수입니다.\n",
    "# async def preprocessing(csv_path, doing_date):\n",
    "#     # 저장한 CSV 파일 다시 읽어오기\n",
    "#     #csv_path = str(news_code) + \"-\" + doing_date + \".csv\"\n",
    "#     print(doing_date + \" 데이터 처리 시작\")\n",
    "#     save_folder = \"done-\" + doing_date[:6]\n",
    "#     df = pd.read_table(csv_path, sep=',')\n",
    "#     data = df['news']\n",
    "#     text_data = []\n",
    "\n",
    "#     specific = 0\n",
    "#     data_count = 0\n",
    "\n",
    "#     # 뉴스 기사 하나 단위\n",
    "#     for sentence in data:\n",
    "#         final_data = []\n",
    "#         data_count += 1\n",
    "#         temp_data = []\n",
    "#         exist_data = []\n",
    "#         specific_data = []\n",
    "#         try:\n",
    "#             #- 토큰화\n",
    "#             s = kkma.sentences(sentence)    # 문장 단위로 자른 데이터\n",
    "#             for one in s:\n",
    "#                 temp_data = tokenizer.morphs(one) \n",
    "#                 #- 불용어 제거\n",
    "#                 temp_data = [word for word in temp_data if not word in stopwords]\n",
    "#                 exist_data= [word for word in temp_data if word in containwords]\n",
    "#                 specific_data = [word for word in temp_data if word in specific_words]\n",
    "#                 if len(exist_data) >= 4 or len(specific_data) >=1:\n",
    "#                     final_data.append(one)\n",
    "#             final_data = list(map(''.join, final_data))\n",
    "#             if len(final_data) > 0 :\n",
    "#                 text_data.append(final_data)\n",
    "#         except:\n",
    "#             continue\n",
    "#         if data_count >= stop_count:\n",
    "#             print(doing_date + \" 뉴스 기사\" + str(stop_count) + \" 개 완료.\")\n",
    "#             data_count = 0\n",
    "#             #await asyncio.sleep(0.1)\n",
    "#         #print(\"가능한 단어는 = \" + str(len(exist_data)))\n",
    "#     text_data = list(map(' '.join, text_data))\n",
    "#     filtered = pd.DataFrame({'news': text_data})\n",
    "#     # 폴더가 없다면 년월에 해당하는 폴더 생성\n",
    "#     try:\n",
    "#         if not os.path.exists(save_folder):\n",
    "#             os.makedirs(save_folder)\n",
    "#     except:\n",
    "#         print(doing_date)\n",
    "#     # csv 파일로 저장\n",
    "#     now_path = save_folder + \"/\" + doing_date + \".json\"\n",
    "#     filtered.to_json(now_path, orient='values', force_ascii=False, indent=4)\n",
    "\n",
    "#     if os.path.exists(now_path):\n",
    "#         print('{} File Saved!'.format(now_path))\n",
    "\n",
    "async def preprocessing(csv_list: list, date_list: list):\n",
    "    # 저장한 CSV 파일 다시 읽어오기\n",
    "    tasks = []\n",
    "    for csv_path, doing_date in zip(csv_list, date_list) :\n",
    "        task = news_filtering(csv_path, doing_date)\n",
    "        tasks.append(task)\n",
    "\n",
    "    \n",
    "    print(\"task 적재 완료\")\n",
    "    await asyncio.gather(*tasks)\n",
    "    # save_folder = \"done-\" + doing_date[:6]\n",
    "    # df = pd.read_table(csv_path, sep=',')\n",
    "    # data = df['news']\n",
    "    # text_data = []\n",
    "\n",
    "    # specific = 0\n",
    "    # data_count = 0\n",
    "\n",
    "    # # 뉴스 기사 하나 단위\n",
    "    # for sentence in data:\n",
    "    #     final_data = []\n",
    "    #     data_count += 1\n",
    "    #     temp_data = []\n",
    "    #     exist_data = []\n",
    "    #     specific_data = []\n",
    "    #     try:\n",
    "    #         #- 토큰화\n",
    "    #         s = kkma.sentences(sentence)    # 문장 단위로 자른 데이터\n",
    "    #         for one in s:\n",
    "    #             temp_data = tokenizer.morphs(one) \n",
    "    #             #- 불용어 제거\n",
    "    #             temp_data = [word for word in temp_data if not word in stopwords]\n",
    "    #             exist_data= [word for word in temp_data if word in containwords]\n",
    "    #             specific_data = [word for word in temp_data if word in specific_words]\n",
    "    #             if len(exist_data) >= 4 or len(specific_data) >=1:\n",
    "    #                 final_data.append(one)\n",
    "    #         final_data = list(map(''.join, final_data))\n",
    "    #         if len(final_data) > 0 :\n",
    "    #             text_data.append(final_data)\n",
    "    #     except:\n",
    "    #         continue\n",
    "    #     if data_count >= stop_count:\n",
    "    #         print(doing_date + \" 뉴스 기사\" + str(stop_count) + \" 개 완료.\")\n",
    "    #         data_count = 0\n",
    "    #         #await asyncio.sleep(0.1)\n",
    "    #     #print(\"가능한 단어는 = \" + str(len(exist_data)))\n",
    "    # text_data = list(map(' '.join, text_data))\n",
    "    # filtered = pd.DataFrame({'news': text_data})\n",
    "    # # 폴더가 없다면 년월에 해당하는 폴더 생성\n",
    "    # try:\n",
    "    #     if not os.path.exists(save_folder):\n",
    "    #         os.makedirs(save_folder)\n",
    "    # except:\n",
    "    #     print(doing_date)\n",
    "    # # csv 파일로 저장\n",
    "    # now_path = save_folder + \"/\" + doing_date + \".json\"\n",
    "    # filtered.to_json(now_path, orient='values', force_ascii=False, indent=4)\n",
    "\n",
    "    # if os.path.exists(now_path):\n",
    "    #     print('{} File Saved!'.format(now_path))\n",
    "\n",
    "\n",
    "# 생각 생각 생각을 다시 해봅시다...\n",
    "# 뉴스 기사가 하루에 대충 4000개니까\n",
    "# 하루에 500개씩 단위를 끊어서 해 주는 것이 맞다...\n",
    "# 이게 맞는지는 모르겠지만\n",
    "# url처럼 500개씩 받아서 받으면 형태소 처리해주고 append...\n",
    "# 해보고 안되면 도르마무 \n",
    "# 라고 했는데 애초에... 거 뭐냐 데이터를 따로 받는게 안되는군...\n",
    "async def news_filtering(csv_path, doing_date) :\n",
    "    print(doing_date + \"뉴스 데이터 필터링 시작\")\n",
    "    save_folder = \"done-\" + doing_date[:6]\n",
    "    async with aiofiles.open(csv_path, encoding='utf-8') as open_csv:\n",
    "        df = pd.read_table(open_csv, sep=',')\n",
    "    data = df['news']\n",
    "    text_data = []\n",
    "\n",
    "    specific = 0\n",
    "    data_count = 0\n",
    "\n",
    "    # 뉴스 기사 하나 단위\n",
    "    for sentence in data:\n",
    "        final_data = []\n",
    "        data_count += 1\n",
    "        temp_data = []\n",
    "        exist_data = []\n",
    "        specific_data = []\n",
    "        try:\n",
    "            #- 토큰화\n",
    "            s = kkma.sentences(sentence)    # 문장 단위로 자른 데이터\n",
    "            for one in s:\n",
    "                temp_data = tokenizer.morphs(one) \n",
    "                #- 불용어 제거\n",
    "                temp_data = [word for word in temp_data if not word in stopwords]\n",
    "                exist_data= [word for word in temp_data if word in containwords]\n",
    "                specific_data = [word for word in temp_data if word in specific_words]\n",
    "                if len(exist_data) >= 4 and len(specific_data) >=1 or len(specific_data)>=2:\n",
    "                    final_data.append(one)\n",
    "            final_data = list(map(''.join, final_data))\n",
    "            if len(final_data) > 0 :\n",
    "                text_data.append(final_data)\n",
    "        except:\n",
    "            continue\n",
    "        if data_count >= stop_count:\n",
    "            print(doing_date + \" 뉴스 기사\" + str(stop_count) + \" 개 완료.\")\n",
    "            data_count = 0\n",
    "            #await asyncio.sleep(0.1)\n",
    "        #print(\"가능한 단어는 = \" + str(len(exist_data)))\n",
    "    text_data = list(map(' '.join, text_data))\n",
    "    filtered = pd.DataFrame({'news': text_data})\n",
    "    # 폴더가 없다면 년월에 해당하는 폴더 생성\n",
    "    try:\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "    except:\n",
    "        print(doing_date)\n",
    "    # csv 파일로 저장\n",
    "    now_path = save_folder + \"/\" + doing_date + \".json\"\n",
    "    filtered.to_json(now_path, orient='values', force_ascii=False, indent=4)\n",
    "\n",
    "    if os.path.exists(now_path):\n",
    "        print('{} File Saved!'.format(now_path))\n",
    "\n",
    "\n",
    "\n",
    "# 5년치 데이터 형태소 분석\n",
    "async def main():\n",
    "    start_date = '20190101'\n",
    "    end_date = '20190110'\n",
    "    doing_date = start_date\n",
    "    tasks = []\n",
    "    count_days = 0\n",
    "    csv_list=[]\n",
    "    date_list=[]\n",
    "    while(doing_date <= end_date):\n",
    "        # 저장한 CSV 파일 다시 읽어오기\n",
    "        csv_path = doing_date[:6] + \"/\" + str(news_code) + \"-\" + str(doing_date) + \".csv\"\n",
    "        # print(csv_path)\n",
    "        try:\n",
    "            if os.path.exists(csv_path):\n",
    "                print(csv_path)\n",
    "                csv_list.append(csv_path)\n",
    "                date_list.append(doing_date)\n",
    "                #task = preprocessing(csv_path, doing_date)\n",
    "                count_days += 1\n",
    "                #tasks.append(task)\n",
    "\n",
    "            # 3일 단위로 데이터 가져오기\n",
    "            if count_days >= 10 or doing_date == end_date:\n",
    "                await preprocessing(csv_list, date_list)\n",
    "                #tasks = []\n",
    "                csv_list =[]\n",
    "                date_list = []\n",
    "                count_days = 0\n",
    "                await asyncio.sleep(0.5)  # 부하로 인한 차단을 막기 위해 일시정지 후 재시작\n",
    "        except:\n",
    "            print(\"error발생, 넘어갑니다.\")\n",
    "            error_msg = traceback.format_exc()\n",
    "            print(error_msg)\n",
    "            #continue\n",
    "\n",
    "        # 날짜 +1 해주기\n",
    "        doing = datetime.datetime.strptime(doing_date, '%Y%m%d')\n",
    "        doing = doing + datetime.timedelta(days = 1)\n",
    "        doing_date = datetime.datetime.strftime(doing, \"%Y%m%d\")\n",
    "\n",
    "await main()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ec0e0b5a8bc3ea7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
